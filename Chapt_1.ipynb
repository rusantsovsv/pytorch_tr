{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-представление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 1.1 Генерация свернутого унитарного или бинарного представления с помощью sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['Time flies flies like an arrow.', 'Fruit flies like a banana.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['an', 'arrow', 'banana', 'flies', 'fruit', 'like', 'time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_vectorizer = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x164fbb88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(one_hot, annot=True, cbar=False, xticklabels=vocab, yticklabels=['Предложение 2', 'Предложение 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF представление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 1.2 Генерация TF-IDF-представления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42519636, 0.42519636, 0.        , 0.60506143, 0.        ,\n",
       "        0.30253071, 0.42519636],\n",
       "       [0.        , 0.        , 0.57615236, 0.40993715, 0.57615236,\n",
       "        0.40993715, 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1802c208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=vocab, yticklabels=['Предложение 2', 'Предложение 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9581, 0.7144, 0.8957],\n",
      "        [0.7067, 0.2630, 0.2756],\n",
      "        [0.1727, 0.9382, 0.3951],\n",
      "        [0.0719, 0.4118, 0.2145],\n",
      "        [0.3439, 0.5002, 0.8426]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем вспомогательную функцию, описывающую различные характеристики тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(x):\n",
    "    print(f'Тип тензора: {x.type()}')\n",
    "    print(f'Размерность тензора: {x.shape}')\n",
    "    print(f'Значения тензора: \\n{x}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0.9411, 0.4547, 0.1932],\n",
      "        [0.8223, 0.3562, 0.1063]])\n",
      "\n",
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0.1986, 0.3061, 1.0440],\n",
      "        [0.9070, 0.2279, 0.3439]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.rand(2, 3))    # случайное равномерное распределение\n",
    "describe(torch.randn(2, 3))   # случайное нормальное распределение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.zeros(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.fill_(5)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53210376, 0.53682294, 0.80362703],\n",
       "       [0.91499237, 0.64333994, 0.18523974]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy = np.random.rand(2,3)\n",
    "npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.DoubleTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0.5321, 0.5368, 0.8036],\n",
      "        [0.9150, 0.6433, 0.1852]], dtype=torch.float64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.from_numpy(npy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы и размер тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2, 3], \n",
    "                       [4, 5, 6]])\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.long()\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]], dtype=torch.int64)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.float()\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операции над тензорами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[ 0.3717,  0.4919,  1.3695],\n",
      "        [-0.8162, -1.2428,  0.3855]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[ 0.7434,  0.9839,  2.7389],\n",
      "        [-1.6324, -2.4856,  0.7709]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(x + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[ 0.7434,  0.9839,  2.7389],\n",
      "        [-1.6324, -2.4856,  0.7709]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(x.add(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.10** Операции над отдельными измерениями тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([6])\n",
      "Значения тензора: \n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = x.view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([3])\n",
      "Значения тензора: \n",
      "tensor([3, 5, 7])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2])\n",
      "Значения тензора: \n",
      "tensor([ 3, 12])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.sum(x, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([3, 2])\n",
      "Значения тензора: \n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.transpose(x, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обращение по индексу, срезы и объединения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.11** Выполнение срезов и обращение по индексу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([1, 2])\n",
      "Значения тензора: \n",
      "tensor([[0, 1]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(x[:1, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([])\n",
      "Значения тензора: \n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(x[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.12** Сложный доступ по индексам: обращение по индексам к несмежным участкам тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 2])\n",
      "Значения тензора: \n",
      "tensor([[0, 1],\n",
      "        [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 1])\n",
    "describe(torch.index_select(x, dim=1, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices = torch.LongTensor([0, 0])\n",
    "describe(torch.index_select(x, dim=0, index=indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.13** Конкатенация тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).view(2, 3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([4, 3])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.cat([x, x], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 6])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.cat([x, x], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 2, 3])\n",
      "Значения тензора: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.stack([x, x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.14** Операции линейной алгебры над тензорами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.LongTensor\n",
      "Размерность тензора: torch.Size([2, 3])\n",
      "Значения тензора: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.arange(6).view(2, 3)\n",
    "describe(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.ones(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([3, 2])\n",
      "Значения тензора: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x2[:, 1] += 1\n",
    "describe(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 2])\n",
      "Значения тензора: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(torch.mm(x1.float(), x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тензоры и графы вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.15** Создание тензоров для вспомогательных операций работы с градиентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 2])\n",
      "Значения тензора: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([2, 2])\n",
      "Значения тензора: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([])\n",
      "Значения тензора: \n",
      "21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.FloatTensor\n",
      "Размерность тензора: torch.Size([])\n",
      "Значения тензора: \n",
      "21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "describe(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2500, 2.2500],\n",
       "        [2.2500, 2.2500]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.16** Создание CUDA-тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# предпочтительный метод: аппаратно-независимое создание экземпляров тензоров\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип тензора: torch.cuda.FloatTensor\n",
      "Размерность тензора: torch.Size([3, 3])\n",
      "Значения тензора: \n",
      "tensor([[0.9787, 0.2838, 0.5747],\n",
      "        [0.6526, 0.5668, 0.2550],\n",
      "        [0.6774, 0.9479, 0.3523]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 3).to(device)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример 1.17** Совместное использование CUDA- и CPU- тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8855, 0.1920, 0.4274],\n",
       "        [0.3098, 0.7277, 0.0408],\n",
       "        [0.6742, 0.7018, 0.0092]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cuda:0 but got device cpu",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-cd60f97aa77f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cuda:0 but got device cpu"
     ]
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8642, 0.4759, 1.0021],\n",
       "        [0.9624, 1.2945, 0.2959],\n",
       "        [1.3515, 1.6497, 0.3615]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.to(cpu_device)\n",
    "x = x.to(cpu_device)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Упражнения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№1 Создайте двумерный тензор, после чего добавьте в него новое измерение размером 1 перед измерением 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2224,  1.1801,  0.3212],\n",
       "        [ 0.0599,  0.6940, -0.0024],\n",
       "        [-0.4058, -1.7246, -0.5929]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2224,  1.1801,  0.3212],\n",
       "        [ 0.0599,  0.6940, -0.0024],\n",
       "        [-0.4058, -1.7246, -0.5929]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2276, -0.3047, -0.6833],\n",
       "         [-0.5242, -0.6914, -0.1703],\n",
       "         [-0.7792,  0.6193, -0.7097]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 2 Удалите дополнительное измерение, которое вы только что добавили в предыдущий тензор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2224,  1.1801,  0.3212],\n",
       "         [ 0.0599,  0.6940, -0.0024],\n",
       "         [-0.4058, -1.7246, -0.5929]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2224,  1.1801,  0.3212],\n",
       "        [ 0.0599,  0.6940, -0.0024],\n",
       "        [-0.4058, -1.7246, -0.5929]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 3 Создайте случайный тензор формой 5 × 3 в интервале [3, 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(3, 7, (5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 5],\n",
       "        [6, 3, 4],\n",
       "        [3, 6, 3],\n",
       "        [4, 5, 4],\n",
       "        [5, 6, 3]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 4 Создайте тензор со значениями, взятыми из нормального распределения (математическое ожидание = 0, стандартное отклонение = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1741, -0.7084,  0.2643],\n",
       "        [-1.1925, -0.4294,  1.4478],\n",
       "        [ 1.0027, -0.7672,  0.8828]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 5 Извлеките индексы всех ненулевых элементов из тензора torch.Tensor([1, 1, 1, 0, 1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1, 1, 1, 0, 1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x == 1).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 6 Создайте случайный тензор размером (3,1), а затем горизонтально разместите в ряд четыре его копии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7723],\n",
       "        [0.4061],\n",
       "        [0.1698]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7723, 0.7723, 0.7723, 0.7723],\n",
       "        [0.4061, 0.4061, 0.4061, 0.4061],\n",
       "        [0.1698, 0.1698, 0.1698, 0.1698]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, x, x, x], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 7 Верните пакетное произведение двух трехмерных матриц (a=torch.rand(3,4,5), b=torch.rand(3,5,4))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8086, 0.3613, 0.0420, 0.9585, 0.2083],\n",
       "         [0.2285, 0.4885, 0.9350, 0.2151, 0.0879],\n",
       "         [0.1473, 0.4601, 0.4137, 0.2963, 0.8665],\n",
       "         [0.7993, 0.9235, 0.2063, 0.3465, 0.0635]],\n",
       "\n",
       "        [[0.2646, 0.4662, 0.2647, 0.4845, 0.4956],\n",
       "         [0.1032, 0.3395, 0.9050, 0.8150, 0.1846],\n",
       "         [0.8875, 0.1278, 0.9983, 0.4381, 0.7180],\n",
       "         [0.8959, 0.8092, 0.8347, 0.4973, 0.9642]],\n",
       "\n",
       "        [[0.1298, 0.1829, 0.0410, 0.1582, 0.4198],\n",
       "         [0.8423, 0.0252, 0.8942, 0.0676, 0.0639],\n",
       "         [0.1871, 0.2027, 0.1065, 0.1593, 0.2963],\n",
       "         [0.0179, 0.3508, 0.3866, 0.5238, 0.5766]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3, 4, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3970, 0.9217, 0.2955, 0.3079],\n",
       "         [0.0060, 0.5157, 0.3798, 0.8995],\n",
       "         [0.0819, 0.7639, 0.4163, 0.4569],\n",
       "         [0.5777, 0.8973, 0.1900, 0.5793],\n",
       "         [0.5712, 0.3610, 0.0263, 0.2207]],\n",
       "\n",
       "        [[0.9897, 0.6891, 0.5963, 0.0151],\n",
       "         [0.8194, 0.4247, 0.9078, 0.8178],\n",
       "         [0.9490, 0.5800, 0.4531, 0.0169],\n",
       "         [0.6471, 0.7151, 0.8931, 0.6670],\n",
       "         [0.4840, 0.6010, 0.2822, 0.4386]],\n",
       "\n",
       "        [[0.3893, 0.2117, 0.4741, 0.7825],\n",
       "         [0.6248, 0.0612, 0.9084, 0.6364],\n",
       "         [0.6455, 0.0763, 0.6755, 0.3445],\n",
       "         [0.5950, 0.0698, 0.8897, 0.3586],\n",
       "         [0.3904, 0.0524, 0.4020, 0.8127]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(3, 5, 4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.bmm(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9993, 1.8989, 0.5812, 1.1944],\n",
       "         [0.3447, 1.4015, 0.6855, 1.0809],\n",
       "         [0.7612, 1.2677, 0.4695, 1.0111],\n",
       "         [0.5762, 1.7043, 0.7403, 1.3857]],\n",
       "\n",
       "        [[1.4484, 1.1781, 1.2735, 0.9303],\n",
       "         [1.8558, 1.4339, 1.5597, 0.9191],\n",
       "         [2.5615, 1.9897, 1.6914, 0.7420],\n",
       "         [3.1303, 2.3802, 2.3632, 1.4440]],\n",
       "\n",
       "        [[0.4493, 0.0749, 0.5650, 0.6301],\n",
       "         [0.9860, 0.2561, 1.1121, 1.0594],\n",
       "         [0.4787, 0.0868, 0.6056, 0.6100],\n",
       "         [1.0124, 0.1216, 1.2860, 1.0268]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№ 8 Верните пакетное произведение трехмерной и двумерной матриц (a=torch.rand(3,4,5), b=torch.rand(5,4))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5163, 0.5648, 0.2860, 0.1039, 0.0620],\n",
       "         [0.9225, 0.5741, 0.7846, 0.0670, 0.3632],\n",
       "         [0.6904, 0.4371, 0.8789, 0.7457, 0.0965],\n",
       "         [0.9629, 0.1053, 0.3343, 0.9174, 0.8256]],\n",
       "\n",
       "        [[0.2223, 0.6089, 0.7947, 0.7899, 0.0601],\n",
       "         [0.4773, 0.9594, 0.4577, 0.0751, 0.8371],\n",
       "         [0.6889, 0.4001, 0.5246, 0.8074, 0.7519],\n",
       "         [0.1673, 0.8412, 0.9327, 0.8099, 0.3110]],\n",
       "\n",
       "        [[0.8472, 0.1284, 0.3582, 0.9938, 0.2208],\n",
       "         [0.4981, 0.9598, 0.1061, 0.3540, 0.9263],\n",
       "         [0.1347, 0.5672, 0.9807, 0.3386, 0.6488],\n",
       "         [0.1572, 0.5568, 0.9797, 0.6286, 0.9021]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,4,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9192, 0.1305, 0.8037, 0.3265],\n",
       "        [0.6996, 0.1770, 0.4145, 0.4983],\n",
       "        [0.0921, 0.6571, 0.5961, 0.4638],\n",
       "        [0.4401, 0.8066, 0.9182, 0.8449],\n",
       "        [0.8254, 0.1535, 0.9902, 0.7246]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(5,4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9192, 0.1305, 0.8037, 0.3265],\n",
       "         [0.6996, 0.1770, 0.4145, 0.4983],\n",
       "         [0.0921, 0.6571, 0.5961, 0.4638],\n",
       "         [0.4401, 0.8066, 0.9182, 0.8449],\n",
       "         [0.8254, 0.1535, 0.9902, 0.7246]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9929, 0.4486, 0.9763, 0.7153],\n",
       "         [1.6511, 0.8474, 1.8683, 1.2710],\n",
       "         [1.4292, 1.3613, 2.0403, 1.5508],\n",
       "         [2.0748, 1.2306, 2.6767, 1.8952]],\n",
       "\n",
       "        [[1.1007, 1.3053, 1.6896, 1.4555],\n",
       "         [1.8760, 0.7219, 1.9520, 1.5162],\n",
       "         [1.9374, 1.2721, 2.5182, 1.8946],\n",
       "         [1.4413, 1.4846, 2.0908, 1.8160]],\n",
       "\n",
       "        [[1.5212, 1.2042, 2.0788, 1.5064],\n",
       "         [2.0594, 0.7323, 2.1037, 1.6604],\n",
       "         [1.2955, 1.1350, 1.8813, 1.5376],\n",
       "         [1.6455, 1.4083, 2.4117, 1.9679]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = torch.bmm(a, b.unsqueeze(0).expand(a.size(0), *b.size()))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
